{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers.models.gpt2 import GPT2Config, GPT2LMHeadModel, GPT2Tokenizer\n",
    "from transformers import BertTokenizer\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "from vocab.tokenization import SMILESBPETokenizer\n",
    "from model.GPT2ModelWithPreFixTuning import GPT2LMHeadMoelWithPrefixTuning\n",
    "from pytorch_lightning import Trainer\n",
    "import os\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import RDLogger\n",
    "RDLogger.DisableLog('rdApp.*')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Checkpoint and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory to serialize a tokenizer and model.\n",
    "checkpoint = \"ckpt\"\n",
    "tokenizer_filename = \"vocab/tokenizer.json\"\n",
    "\n",
    "tokenizer = SMILESBPETokenizer.get_hf_tokenizer(\n",
    "    tokenizer_filename, model_max_length=256)\n",
    "model = GPT2LMHeadMoelWithPrefixTuning.from_pretrained(checkpoint)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加载ECloud数据 这里加载了7个\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecloud_rootdir = 'generation/eclouds'\n",
    "ecloud_fnames =  os.listdir(ecloud_rootdir)\n",
    "# sorted by int value\n",
    "ecloud_fnames = sorted(ecloud_fnames)\n",
    "ecloud_fnames = [os.path.join(ecloud_rootdir, fname) for fname in ecloud_fnames]\n",
    "eclouds = np.zeros((len(ecloud_fnames), 64, 64, 64), dtype=np.float16)\n",
    "print(\"Shape of Eclouds: \", eclouds.shape)\n",
    "for i, fname in tqdm(enumerate(ecloud_fnames), total=len(ecloud_fnames)):\n",
    "    eclouds[i] = np.load(fname)\n",
    "# convert eclouds to torch Float32\n",
    "eclouds = torch.from_numpy(eclouds).float()\n",
    "print(eclouds[0].dtype)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "准备生成使用的get_attention_mask以及get_prompt函数，这里get_prompt需要先load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attention_mask_for_generation(prefix_len=128, bz=1):\n",
    "    # attention mask for generation\n",
    "    # 1 for prefix tokens, 0 for generated tokens\n",
    "    # plus 1 for bos token\n",
    "    attention_mask = torch.ones((bz, prefix_len + 1)).long()\n",
    "    return attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt(ecloud):\n",
    "    prefix_encoder = model.prefix_encoder\n",
    "    past_key_values = prefix_encoder(ecloud)\n",
    "    return past_key_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = get_prompt(eclouds)\n",
    "print(len(prompts)) # 12 layers\n",
    "print(prompts[0].shape) # each layer [2, 1, 12, 128, 64] k&v, bs, num_heads, prefix_len, d_model_per_head"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "生成过程 根据输入电子云生成smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_generated = 10\n",
    "smiles_start = torch.LongTensor([[tokenizer.bos_token_id]])\n",
    "generated_smiles_list = []\n",
    "# sequential generation\n",
    "# for i in range(len(eclouds)):\n",
    "#     temp_smiles_list = []\n",
    "#     past_key_values = get_prompt(eclouds[i].unsqueeze(0))\n",
    "#     for _ in tqdm(range(n_generated), total=n_generated):\n",
    "#         generated_ids = model.generate(input_ids=smiles_start,\n",
    "#                                     max_length=512-129,\n",
    "#                                     top_k=50,\n",
    "#                                     top_p=0.96,\n",
    "#                                     repetition_penalty=0.8,\n",
    "#                                     temperature=0.9,\n",
    "#                                     do_sample=True,\n",
    "#                                     attention_mask=attention_mask,\n",
    "#                                     pad_token_id=tokenizer.eos_token_id,\n",
    "#                                     past_key_values=past_key_values,\n",
    "#                                     num_return_sequences=1)\n",
    "#         temp_smiles_list.append(tokenizer.decode(generated_ids[0], skip_special_tokens=True))\n",
    "#     print(temp_smiles_list)\n",
    "#     generated_smiles_list.append(temp_smiles_list)\n",
    "\n",
    "# batch generation\n",
    "generated_smiles_list = [[] for _ in range(len(eclouds))]\n",
    "attention_mask = get_attention_mask_for_generation(bz=len(eclouds))\n",
    "for _ in tqdm(range(n_generated), total=n_generated):\n",
    "    generated_ids = model.generate(input_ids=smiles_start.repeat(len(eclouds), 1),\n",
    "                                    max_length=512-129,\n",
    "                                    top_k=50,\n",
    "                                    top_p=0.96,\n",
    "                                    repetition_penalty=0.8,\n",
    "                                    temperature=0.9,\n",
    "                                    do_sample=True,\n",
    "                                    attention_mask=attention_mask,\n",
    "                                    pad_token_id=tokenizer.eos_token_id,\n",
    "                                    past_key_values=prompts,\n",
    "                                    num_return_sequences=1)\n",
    "    temp_generated_smiles_list = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "    print(len(generated_smiles_list))\n",
    "    for i in range(len(eclouds)):\n",
    "        generated_smiles_list[i].append(temp_generated_smiles_list[i])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里load了一下参考的sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf_root = 'generation/sdfs'\n",
    "sdf_names = os.listdir(sdf_root)\n",
    "sdf_names = sorted(sdf_names)\n",
    "sdf_names = [os.path.join(sdf_root, fname) for fname in sdf_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_smiles_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "write_root = 'generation/gen_res'\n",
    "count = 0\n",
    "valid_count = 0\n",
    "for i, temp_smiles_list in enumerate(generated_smiles_list):\n",
    "    for j, smiles in enumerate(temp_smiles_list):\n",
    "        count += 1\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is None:\n",
    "            continue\n",
    "        mol = Chem.AddHs(mol)\n",
    "        AllChem.EmbedMolecule(mol, randomSeed=42)\n",
    "        conformer = mol.GetConformer()\n",
    "        # mol_coord = torch.tensor(conformer.GetPositions()).float()\n",
    "        # target_coord = target_positions[0]\n",
    "        # trans_mat = Chem.rdMolAlign.GetAlignmentTransform(mol, target_mol)\n",
    "        # Chem.rdMolTransforms.TransformConformer(conformer, trans_mat)\n",
    "        Chem.SDWriter(os.path.join(write_root, sdf_names[i].split('/')[-1].split('.')[0] + f'_gen_res_{j}.sdf')).write(mol)\n",
    "        valid_count += 1\n",
    "print(\"Validity: \", valid_count / count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n",
      "58.2\n",
      "276.38\n"
     ]
    }
   ],
   "source": [
    "from rdkit import Chem\n",
    "from data.utils import *\n",
    "mol = Chem.MolFromSmiles('CCCC(NC(=O)C(C)C)C(=O)Nc1ccc(C)cc1')\n",
    "print(calculate_hba(mol))\n",
    "print(calculate_hbd(mol))\n",
    "print(calculate_tpsa(mol))\n",
    "print(calculate_mw(mol))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.FloatTensor([2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('carbon')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8cb457098628399098f8244ea6d862b61e5b409c4fe20c91d3202c562013c713"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
